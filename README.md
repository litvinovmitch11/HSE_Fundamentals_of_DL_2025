<center><h1>Основы глубокого обучение</h1></center>

## Прериквизиты

- **Уверенное владение Python.** Свободно использовать Python для разработки кода, работать с базовыми структурами данных, функциями, модулями и классами. Также должны быть навыки работы с основными библиотеками, такими как NumPy, Pandas и Matplotlib, необходимыми для анализа данных и визуализации.
- **Навыки обработки данных.** Понимание ключевых этапов очистки, нормализации, аугментации и визуализации данных. Опыт работы с текстовыми, визуальными или акустическими данными, включая использование инструментов для их обработки, таких как OpenCV, Librosa или Scikit-learn.
- **Математический базис.** Знание линейной алгебры (матрицы, векторы, собственные значения) и основ анализа (градиенты, оптимизация). Эти концепции позволят лучше понять работу нейросетей и алгоритмов глубокого машинного обучения.
- **Основы теории вероятностей и статистики.** Необходимо иметь представление о вероятностных распределениях, гипотезах, методах оценки параметров и визуализации данных. Также будет плюсом знание методов статистического анализа или корреляция.
- **Знакомство с основами машинного обучения.** Базовые знания алгоритмов классификации, регрессии, кластеризации и метрик оценки моделей. Опыт реализации простых моделей с использованием Scikit-learn или аналогичных библиотек.
- **Работа с библиотеками для машинного обучения.** Начальное знакомство с библиотеками PyTorch или TensorFlow, включая написание простого кода (функций, классов) для создания нейросетей, тренировки моделей и работы с GPU.
- **Технический английский.** Умение читать документацию, статьи и руководства на английском языке для освоения современных библиотек и технологий машинного обучения.

## Темы лекций и семинаров

### Лекции

1. [**Введение в глубокое обучение.**](https://github.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/blob/main/tutorials/1.ipynb) Введение в концепции глубокого обучения, история и основные области применения. Основные архитектуры нейросетей, включая сверточные сети (CNN) и рекуррентные сети (RNN). Обзор современных библиотек, таких как PyTorch и Hugging Face.
2. [**Основы нейросетей.**](https://github.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/blob/main/tutorials/2.ipynb) Принципы работы нейросетей: функции активации и потерь, методы оптимизации и механизм обратного распространения ошибки. Роль гиперпараметров и способы их настройки.
3. [**Классические архитектуры глубокого обучения для работы с последовательными данными.**](https://github.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/blob/main/tutorials/3.ipynb) Обзор классических архитектур.
4. **Современные архитектуры глубокого обучения.** Обзор современных архитектур, включая семейства трансформеров, xLSTM и Mamba. Применение данных архитектур для анализа последовательных данных, изображений и мультимодальной интеграции.
5. **Регуляризация и улучшение надежности моделей.** Методы предотвращения переобучения. Оценка надежности моделей через анализ неопределенности и построение доверительных интервалов.
6. **Мультимодальные модели глубокого обучения.** Принципы работы с мультимодальными данными. Интеграция текстовой, визуальной и акустической модальностей в единую нейросетевую модель. Использование современных нейросетевых архитектур, для анализа и предсказания в современных мультимодальных задачах.
7. **Тонкая настройка предобученных моделей.** Принципы transfer learning и fine-tuning. Практическое применение предобученных нейросетевых моделей, для адаптации к новым задачам.
8. **Оптимизация гиперпараметров.** Автоматизация выбора гиперпараметров с помощью методов байесовской оптимизации и поиска по сетке (Grid Search). Работа с наборами данных разной размерности и эффективное управление вычислительными ресурсами.
9. **Self-supervised и zero-shot learning.** Современные подходы к обучению без учителя и нулевому обучению. Их применение для улучшения производительности нейросетевых моделей на ограниченных наборах данных.
10. **Заключение и перспективы глубокого обучения.** Обзор пройденных тем и ключевых выводов. Современные тренды в области глубокого машинного обучения.

### Семинары

1. [**Настройка окружения и работа с PyTorch.**](https://github.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/blob/main/tutorials/1.ipynb) Установка и настройка окружения, работа с Jupyter Notebook. Базовая работа с экосистемой Torch, объединяющей библиотеки PyTorch, TorchAudio, TorchVision и TorchText.
2. [**Реализация базовой нейросети.**](https://github.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/blob/main/tutorials/2.ipynb) Построение и обучение простой нейросети для классификации данных. Введение в функции потерь и оптимизаторы.
3. [**Классические архитектуры глубокого обучения для работы с последовательными данными.**](https://github.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/blob/main/tutorials/3.ipynb) Применение классических архитектур для анализа последовательных данных.
4. **Работа с последовательными данными.** Использование рекуррентных нейросетей в том числе и xLSTM для анализа временных рядов или текстов. Извлечение признаков с помощью моделей семейства Mamba.
5. **Сверточные сети и обработка изображений.** Построение сверточной нейросети для классификации изображений. Применение современных методов аугментации данных для повышения качества модели.
6. **Тонкая настройка предобученных моделей.** Настройка и применение предобученных нейросетевых моделей для выполнения специфической задачи, включая обработку текстов или классификацию изображений.
7. **Мультимодальная интеграция данных.** Создание простой нейросетевой модели, работающей с текстами и изображениями. Оценка производительности мультимодальных моделей.
8. **Регуляризация и предотвращение переобучения.** Применение методов предотвращения переобучения. Анализ переобучения и тестирование на независимых наборах данных.
9. **Оптимизация гиперпараметров и анализ моделей.** Настройка гиперпараметров с помощью Grid Search или байесовской оптимизации. Визуализация и интерпретация результатов моделей.
10. **Финальный проект.** Разработка модели для решения выбранной задачи (например, классификация изображений, анализ текстов, спектрограмм или мультимодальная интеграция). Оценка результатов, подготовка отчета и презентация проекта.

## Система оценивания

Оценка за курс формируется следующим образом:
Оценка = 0.5 * Домашняя работа + 0.5 * Экзамен (итоговый проект)

### Домашняя работа

Всего предусмотрено **8** домашних заданий, каждое из которых оценивается в **0.5** балла. Задания охватывают различные аспекты применения методов глубокого обучения в задачах обработки естественного языка (NLP), речевых технологий (Speech/Signal Processing) и компьютерного зрения (CV).

Все домашние работы должны быть загружены на **GitHub**, и необходимо отправить ссылку на репозиторий в https://telegram.me/dmitry_ryumin

#### Критерии оценки для домашней работы

- Отлично (8) Выполненная домашняя работа
- Хорошо (6-7) Работа выполнена на 80%
- Удовлетворительно (4-5) Работа выполнена на 50%
- Неудовлетворительно (0-3) Работа выполнена менее чем на 50%

## Экзамен

Для сдачи экзамена по данному курсу необходимо подготовить учебный исследовательский проект. Проект должен быть основан на реальных данных, которые можно взять из открытых источников (например из https://huggingface.co/datasets). В рамках проекта студенты должны провести анализ данных, сформулировать задачу, обучить несколько моделей, выбрать наилучшую и обосновать свой выбор.

Экзамен включает презентацию работы, которая состоит из следующих частей:
- **Цель работы.** Четкое описание задачи, которую предстоит решить с использованием машинного обучения.
- **Описание исходных данных.** Подробное представление данных, включая источник, структуру и ключевые характеристики.
- **Используемые алгоритмы с обоснованием.** Описание применяемых методов и алгоритмов машинного обучения с объяснением, почему они были выбраны для решения задачи.
- **Как измерялось качество моделей.** Описание метрик, использованных для оценки производительности моделей, и методов анализа результатов.
- **Итоговые результаты.** Представление полученных результатов, выводы по сравнению моделей, а также их интерпретация.

На презентацию выделяется 10 минут (5 минут на доклад и 5 минут на вопросы). Допускается выполнение проекта в парах.
Весь код и презентация проекта должны быть загружены на **GitHub**, оформлены с **README файлом**, и необходимо отправить приглашение на репозиторий пользователю **DmitryRyumin**.

Критерии выставления оценок:
- 4 балла можно получить за выполнение домашних заданий (8 заданий по 0.5 балла за каждое, округление в пользу студента; для получения максимума необходимо выполнить все 8 заданий).
- 4 балла можно получить за защиту итогового проекта.
- 2 балла можно получить за выполнение дополнительных требований к проекту (1 балл за каждое):
    - Использование двух и более наборов данных (корпусов) из открытых источников, таких как Hugging Face Datasets.
    - Создание приложения с использованием Gradio, размещенного на Hugging Face, которое позволяет вводить данные для модели и получать результаты.
